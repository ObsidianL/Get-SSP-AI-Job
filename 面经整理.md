## 自我介绍

## 专业基础

一般来说**不会问太多深度学习相关的内容**，可能会挑一些比较基础的问。

### 高频
1. FM系列模型，尤其是FM、FFM、DeepFM，知道原理细节，以及联系和区别，适用场景

   1. xdeepfm, deepfm区别 
   2. wide&deep，deepfm区别
   3. DeepFM为了解决什么问题？  

    

2. FM模型整个公式都会推导

3. 决策树模型，GBDT、XGBDT必须熟悉掌握

   1. GBDT和其他树模型之间的区别？
   2. 决策树?信息增益，信息增益率 gini系数 怎么理解?
   3. 为什么从信息增益换给信息增益率 举个具体的例子?
   4. xgboost 原理?
   5. 树模型怎么选取分裂点?
   6. 特征重要性怎么计算的? 残差怎么理解?
   7. xgb怎么处理分类和回归问题？

4. LR模型

   1. lr是什么loss函数推导，做多分类

5. 推荐系统评价指标，定义公式，含义，优劣

   意义，以及为什么能评价模型

   1. Precision
   2. Recall
   3. AUC

6. wide&deep，其原理以及优势

   1. Widedeep 为什么要分wide  deep，好处？ 

7. embedding

8. word2vec，word2vec的两种方式，如何优化，如何采样

   1. 简述word2vec；
   2. 说说滑动窗口大小以及负采样个数的参数设置以及设置的比例；
   3. 怎么衡量学到的embedding的好坏

9. 模型如何判断过拟合，以及过拟合的解决方法

   【除了Dropout、Batchnormal之类的，还可以说一下决策树是如何防止过拟合的】

10. 模型检验的方法有哪些？

11. 梯度下降的方法有哪些？

12. 准备一个自己最拿手的，实践过的模型，eg. XGB

    1. 了解哪些机器学习模型，举例说明原理？

13. 损失函数有哪些？具体公式？适用场景？

    1. Adam

14. 激活函数有哪些？区别？作用？适用场景？

    1. ReLU

       为什么要用ReLU替代tanh/sigmoid/softmax

       答：ReLU求导的值要么是0要么是1，不会引起梯度消失或梯度爆炸

15. 优化器有哪些？区别？作用？适用场景？

16. Dropout的原理

    1. Dropout的原理 (**为什么训练时有dropout测试时没有dropout，这样会发生scale的偏移吗**)

       答：不会，因为训练时dropout机制会把dropout_rate = p的输出乘以1/(1-p)

17. Batch Normalization的原理

    在mini_batch上进行而不是在整个数据集上进行。在训练集上有BN测试集上没有BN，这样不会发生数值上的偏移，道理类似dropout，即记录下训练集上的BN参数（均值、标准差、\beta、\gamma）作为网络参数的一部分。

18. 朴素贝叶斯公式？

19. 交叉熵公式？

20. wide&deep

    排序阶段wide&deep是怎么架构的？（这里最终节点是sigmoid输出，我给说成softmax了，然后又问了一下softmax的公式和应用）


### 中频
1. xdeepFM
1. word2vec、item2vec、node2vec
1. 神经网络梯度爆炸or消失的原因和解决方法
1. 随机森林
   1. 问了随机森林有了解吗？知道里面的有放回的采样方法吗？

1. 神经网络所有参数可以都初始化为0吗？0.1呢？[见此处](https://zhuanlan.zhihu.com/p/27190255)
1. Attention机制介绍一下？
1. 池化层作用？
1. 机器学习中测试集上效果不好可能有哪些原因造成
1. 卷积神经网络和全连接神经网络区别
1. 哪些算法需要归一化，哪些算法对缺失值不敏感。
1. LDA的原理。LDA如何调参。

### 推荐场景知识

1. 熟悉推荐业务的整个流程：召回、粗排、精排、重排

   1. 了解召回和排序模型吗？
   2. 排序模型你知道哪些？说一下原理？
   3. 各个流程常用的算法

2. 召回

   1. 怎么进行召回
   2. **为什么召回的数量级小，排序模型的效果就好**，为什么不召回更大数量级的候选集。
   3. FM如果用来做召回，应该怎么做？
   4. item_feature如何召回，召回和其他方法有重复的商品时怎么处理？

3. 模型的离线评估

4. 还了解哪些推荐模型？用过吗？有什么体会？

   1. 就可以说出比较前沿的推荐模型了
   2. 了解哪些机器学习模型，举例说明原理？

5. 冷启动

   1. Item和User冷启动如何处理
   2. 用户没有购买商品怎么处理？（冷启动问题）

6. 给你一些很稀疏的特征，用LR还是树模型

7. 如何embedding的？对图片和文本如何提取特征了解吗？

8. 多路召回有重复的item怎么处理？

9. item和user冷启动怎么处理？

10. 说说推荐系统算法大概可以分为哪些种类

11. itemCF的原理，实现过程

12. 冷启动问题

13. exploit－explore问题

14. 样本稀疏

15. 多目标

16. 特征泄漏

17. 离线训练和流式训练指标不一致

    


## 拓展加分

DIN模型

知识图谱在推荐系统中的应用

强化学习在推荐系统中的应用

> **我会让他自己选择一个他拿手的模型进行介绍**。比如之前有一个哥们选了Kmeans，他把Kmeans说出来的时候就在我心里已经扣了点分了。说明他对于他当时提到的其他模型一定都不是非常自信，不然为啥选择最简单的Kmeans？必须要深入思考的。


## 项目

## 算法

## python基础

干货 | 美团推荐算法工程师岗8道面试题分享 - 六十度灰的文章 - 知乎 https://zhuanlan.zhihu.com/p/467828002

问题2：python 垃圾处理机制

在Python中，主要通过引用计数进行垃圾回收；

通过 “标记-清除” 解决容器对象可能产生的循环引用问题；

通过 “分代回收” 以空间换时间的方法提高垃圾回收效率。

也就是说，python采用的是引用计数机制为主，标记-清除和分代收集（隔代回收）两种机制为辅的策略。

问题3：yield 关键字作用

yield是一个类似 return 的关键字，只是这个函数返回的是个生成器，可以节省巨大的时间、空间开销。

Python的shuffle函数内部是如何实现的？【呃。。。没有读过shuffle的源码】说说如果你来实现，你会如何实现？【每次random出一个index，和shuffle过的数组未shuffle部分的头交换】如何评价你提出的算法shuffle的性能？【首先定义两个数组间的“相似度”为两数组各个位置相同的数的个数，运行N次shuffle算法，计算得到的N个无序数组两两之间的相似度之和S，S越小，shuffle算法的无序性越好】

python中函数传递参数是值传递还是引用传递（很坑，两个都不是，见[深入理解python中函数传递参数是值传递还是引用传递](https://www.jb51.net/article/127667.html)）





Python的GIL锁，装饰器？

tuple和list的区别，list的底层实现

然后问了python多线程和c++多线程的区别

python的GIL，申请和释放

## 场景题

问一问对方对推荐的理解。推荐算法究竟解决了什么问题，推荐算法的痛点是什么？我们怎么样来设计特征，在线学习怎么做？



如果让你设计推荐系统，将100个图片按顺序推荐给100个用户，如何设计算法？【答：什么什么矩阵，术语忘了。。。】100万个图片和100万个用户呢？【答：稀疏矩阵】计算这个矩阵的时候，用户的哪些信息可以利用？【浏览、点击、搜索；个人信息】社交媒体可以利用吗？【可以，好友偏好，群组偏好】

大致意思是有个交友软件，用户点击匹配时，系统为用户匹配其他用户，然后开始聊天，系统会记录聊天时长。在已经有一个月的历史数据的情况下，如何设计算法使得匹配到的两个人聊天时间尽可能长？
假设有n个人正在进行匹配，系统已经预估出两两之间的聊天时长，如何使得这n个人匹配后的聊天时长总时长达到最大？



1.自我介绍

2.为什么去字节

3.能给字节带来什么价值

4.觉得自己能得到什么提升

5.字节跳动产品有哪些

6.对抖音的日活有了解吗

7.怎么针对抖音存在的问题进行优化



## 来源

https://www.nowcoder.com/discuss/449777?type=2

https://blog.csdn.net/m0_46162954/article/details/113616986





## 其它

研究三年CV，最后推荐算法上岸：）分享给秋招中零经验CV转推荐的同学一些面试准备:



阅读《深度学习推荐系统》，作者王喆，入门基础知识

熟悉推荐系统中的流程：召回->粗排->精排-->re-rank；以及各个流程中常用的算法

了解推荐模型的整个发展历史，了解每个模型的结构、优缺点、改进方式（看看代码）

考虑一些推荐系统的实际问题，多看看知乎大佬们的回答：

冷启动问题

exploit－explore问题

样本稀疏

多目标

特征泄漏

离线训练和流式训练指标不一致

等等

以上凭印象写了主要学习思路，当时为了转推荐算法大概整理学习了大几十页的资料，没有实际的工作经验，只能加强下自己的理论知识了。后来在某节实习了一段时间，遇到了很好的leader带我，丰富了一些工作上的经验。感觉实际中除了模型之外，数据处理、特征是非常重要的一个环节；其次要深入理解业务，根据应用场景也会设置一些规则（有时候非常有效...）。希望之后在工作里能有更多的感悟吧，争取不当调参侠！



最后说一点转推荐之后的感受，之前觉得研究CV的人太多了所以想换个竞争少点的方向，现在觉得都是围城...；之前觉得CV算法工程师就只做CV，NLP算法工程师就只用文本，现在觉得好像不分家啊...只能说快速学习是一个算法工程师的基本能力，因为工作中啥都得用，啥都得会....



